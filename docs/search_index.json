[["index.html", "La raport intermédiaire Chapitre 1 Application de la méthode LSPIV 1.1 Image preparation 1.2 PIV processing", " La raport intermédiaire Antoine Viguié, Aymane Berriane, Christian Alvarez LeonWang, Wang Meng, PENG Yu 2020-12-07 Chapitre 1 Application de la méthode LSPIV La technique LSPIV (Large Scale Particle Image Velocimetry) permet de mesurer les vitesses de surface d’un écoulement par analyse de séquence d’images. La méthode LSPIV complète se compose de trois parties principales: la préparation de l’image (voir section 1.1 ) le traitement PIV (voir section 1.2 ) l’analyse des données. 1.1 Image preparation La préparation de l’image est nécessaire pour être en mesure de mieux distinguer les motifs en mouvement de l’imagerie et de supprimer les effets de perspective de l’image. La manipulation d’image pour préparer l’imagerie pour l’analyse LSPIV se composent de plusieurs étapes. Subséquemment, ces étapes sont: (1) La correction de distorsion optique, (2) La stabilisation, (3) l’orthorectification et (4) La mise en niveau de gris et la correction du gamma et du contraste. Les trois premières étapes sont appliquées pour garantir la présence de distances égales dans les images. La quatrième étape est utilisée pour améliorer la distinction de la graine de l’arrière-plan et donc s’assurer de la validation de similitude processus est efficace. Il existe plusieurs logiciels qui permettent d’appliquer des options de manipulation d’images, comme OpenCV3(“OpenCV 3.0. OpenCV” 2015) La correction de distorsion optique En raison de la la courbure des lentilles de l’appareil photo, les images peuvent être déformées. Figure 1.1 présente les deux types de distorsions des lentilles les plus fréquentes,la distorsion en barillet et la distorsion en coussinet (Fryer and Brown 1986) , Ces distorsions géométriques sont liées à des facteurs radiaux. Un troisième type de distorsion est distorsion tangentielle, qui se produit lorsque les lentilles ne sont pas parallèles au plan image. Certaines caméras sont capables de faire face à ces distorsions intérieurement. Cependant, la plupart du temps, une certaine quantité de post-traitement est nécessaire pour ajuster les images. Figure 1.1: Les differentes types de distortion. Du gauche à la droit : la grille d’origine, la distorsion en barillet et la distorsion en coussinet. Les formules suivantes sont appliquées pour supprimer la distortion radial (Voir Équation(1.1)) et la distorsion tangentielle (Voir Équation(1.2)) \\[\\begin{equation} \\begin{aligned} x_{corr} = x\\left(1+k_1r^2+k_2r^4+k_3r^6\\right) \\\\y_{corr} = y\\left(1+k_1r^2+k_2r^4+k_3r^6\\right) \\end{aligned} \\tag{1.1} \\end{equation}\\] D’où \\(\\) et \\(\\) sont les coordonnées d’origine; \\(x_{}\\) et \\(y_{}\\) sont les coordonnées corrigés. \\(\\) est la distance entre le point \\(\\left(, \\right)\\) et le centre de la distortion. \\(_1\\), \\(_2\\), et \\(_3\\) sont les coefficients radiales. Pour la distortion en barillet et la distortion en coussinet , \\(_1\\) est respectivemen negative et positive. \\(_2\\) et \\(_3\\) sont négligeables. \\[\\begin{equation} \\begin{aligned} x_{corr} = x+\\left[ 2 p_1 x y+ p_2\\left( r^2+2x^2\\right) \\right]\\\\ y_{corr} = y+\\left[ p_1 \\left(r^2+2 y^2\\right)+ 2p_2xy\\right] \\end{aligned} \\tag{1.2} \\end{equation}\\] D’où \\(_1\\) et \\(_2\\) sont les coefficient de la distortion tangentielle. les différents coefficients sont souvent stockés dans un tableau: \\[\\begin{equation} C_{dis}= \\begin{bmatrix} k_1 &amp; k_2 &amp; p_1 &amp; p_2 &amp; k_3 \\end{bmatrix} \\end{equation}\\] À part du coefficient de distorsion, pour pouvoir corriger l’imagerie, Une conversion entre les coordonnées de distorsion et la résolution de la caméra est fait. Pour cela, la formule est donnée dans l’équation (1.3) \\[\\begin{equation} \\begin{bmatrix} x\\\\ y\\\\ w \\end{bmatrix} = M_{con} \\cdot \\begin{bmatrix} x\\\\ y\\\\ z \\end{bmatrix} \\quad d&#39;où \\quad M_{con} = \\begin{bmatrix} f_x &amp; 0 &amp; c_x\\\\ 0 &amp; f_y &amp; x_y\\\\ 0 &amp; 0 &amp;1 \\end{bmatrix} \\tag{1.3} \\end{equation}\\] D’où \\([, , ]\\) sont les coordonnées d’image homogène 2D et \\([x, y , z]\\) sont les coordonnées de caméra 3D . \\(f_\\) et \\(_\\) sont les longueurs locales de la caméra dans le sens \\(\\) et \\(\\) ,en genéral, ils sont identiques - \\(_\\) et \\(_\\) sont les coordinations de centre optique de la caméra dans le sens \\(\\) et \\(\\). La stabilisation Après avoir appliqué la correction de la distorsion optique , le mouvements d’images possibles peut être supprimé en appliquant la stabilisation de vidéo. Les principales étapes de stabilisation sont (1) l’extraction de points clés sur deux trames séquentielles, (2) faire correspondre les points sur les deux trames, (3) estimer le transformation géométrique, et (4) correction du mouvement. l’orthorectification d’image Pour supprimer les effets de la perspective de l’image – là où les objets sont plus proches de la caméra semble être plus grande que les objets en arrière-plan – , l’orthorectification est appliquée. Lors de l’application d’orthorectification, le système de coordonnées de l’imagerie est transféré à une coordonnée locale système. Pour ce système de coordonnées locales, points de contrôle au sol (GCP) – mis en place à côté du flux – sont utilisés. Pour l’orthorectification processus pour être aussi précis que possible, au moins quatre GCP sont nécessaires, si les images sont capturées perpendiculairement au flux ou lorsque les GCP sont placés au même niveau que le niveau de l’eau. Un minimum de six GCP sont nécessaires lorsque les GCP ne sont pas placés dans le même plan que le niveau d’eau. Sur la Figure 1.2 les différents sites de jaugeage et les configurations sont affichées. Figure 1.2: Nombre de points de contrôle au sol (GCP) nécessaires dans différentes circonstances. Lors de l’utilisation de quatre GCP, les facteurs d’inversion \\(_\\) et \\(_\\) sont déterminé en utilisant la formule indiquée dans l’équation (1.4). \\[\\begin{equation} p_{loc}\\left(x,y\\right)=p_{img}\\left(f_x\\left(x,y\\right), f_y\\left(x,y\\right)\\right) \\tag{1.4} \\end{equation}\\] D’où \\(_ {} \\left (, ,  \\right)\\) est l’emplacement géographique du point de contrôle au sol dans le système de coordonnées local, généralement en métrique units; \\(_ {} \\left (,  \\right)\\) est la coordonnée xy du sol point de contrôle dans l’imagerie, généralement en pixels; et \\(_\\) et \\(_\\) le facteurs d’inversion. Simultanément à ce processus, la résolution de l’image peut être réglée en multipliant les coordonnées \\(_ {} \\left (,  \\right)\\) par les pixels souhaités par coefficient de mètre. Un exemple de le processus d’orthorectification est illustré à la Figure 1.3 . Figure 1.3: Exemple de processus d’orthorectification utilisant quatre GCP, indiqués par des poteaux en bambou le long du ruisseau. Lorsque six (ou plus) GCP sont utilisés - parce que les coordonnées en trois dimensions pour les GCP sont nécessaires - un modèle de sténopé peut être utilisé. Cette méthode est expliqué par (Jodeau et al. 2008) . La mise en niveau de gris et la correction du gamma et du contraste La dernière étape de la préparation de l’image est la conversion du imagerie à une échelle de gris et pour appliquer une correction de contraste et gamma. Une mise à l’échelle des gris est nécessaire pour pouvoir appliquer la validation de similarité entre images vidéo séquentielles. La correction de contraste et gamma est appliquée à améliorer la visibilité des semences. Les corrections de contraste et gamma sont appliqué à l’aide des formules suivantes: \\[\\begin{equation} O_{constract} = \\alpha \\cdot I + \\beta \\tag{1.5} \\end{equation}\\] \\[\\begin{equation} O_{gamma} = \\left(\\frac{I}{255}\\right)^\\frac{1}{\\gamma} \\cdot 255 \\tag{1.6} \\end{equation}\\] where \\(\\alpha\\) and \\(\\beta\\) defines the contrast correction; \\(\\gamma\\) the gamma correction; \\(O_n\\) are the corrected imagery; and \\(I\\) is the original imagery D’où \\(\\alpha\\) et \\(\\beta\\) définit la correction du contraste; \\(\\gamma\\) est la correction de gamma; \\(O_n\\) sont les imageries corrigés; et \\(I\\) est l’imagerie d’origine. 1.2 PIV processing La figure 1.4 montre les étapes du traitement PIV. Pour deux séquentiels cadres, les images sont divisées en cellules de grille. En déterminant validation de similarité - par exemple, une corrélation croisée ou une rapport signal / bruit (Ran et al. 2016 ; Osorio-Cano, Osorio, and Medina 2013) - entre les deux cadres de la zone de recherche, les déplacements peuvent être déterminé. Ces déplacements sont ensuite convertis en vitesse d’écoulement vecteurs. Après avoir appliqué ce processus sur \\(\\) images, un total de \\( 1\\) cartes de vitesse sont créées. Pour chaque carte de vitesse, les résultats peuvent être encore améliorés en appliquant un filtrage supplémentaire basé sur la valeur de similarité dans chaque fenêtre d’interrogation unique, et en remplaçant ces valeurs filtrées par interpolation les cellules de la grille environnantes connues. Ces post-traitements les étapes dépendent du logiciel utilisé ou des résultats requis. Figure 1.4: Vue schématique de la méthode LSPIV où une fenêtre d’interrogation est déterminée (la grille est dessinée plus grande dan généralement appliqué) dans la première image et les graines présentes sont comparées à une zone de recherche dans l’image séquentielle 2 à déterminer leurs déplacements. En multipliant le déplacement par la période de temps de trame, la vitesse est déterminée. Lorsque vous appliquez ceci sur toute l’image, une carte de vitesse d’écoulement de surface peut être créée pour chaque image individuelle. "],["references.html", "References", " References Fryer, John, and Duane Brown. 1986. “Lens Distortion for Close-Range Photogrammetry.” Photogrammetric Engineering and Remote Sensing - PHOTOGRAMM ENG REMOTE SENSING 52 (January): 51–58. Jodeau, M., A. Hauet, A. Paquier, J. Le Coz, and G. Dramais. 2008. “Application and Evaluation of LS-PIV Technique for the Monitoring of River Surface Velocities in High Flow Conditions.” Flow Measurement and Instrumentation 19 (2): 117–27. https://doi.org/10.1016/j.flowmeasinst.2007.11.004. “OpenCV 3.0. OpenCV.” 2015. June 4, 2015. https://opencv.org/opencv-3-0/. Osorio-Cano, Juan David, Andrés F. Osorio, and Raul Medina. 2013. “A Method for Extracting Surface Flow Velocities and Discharge Volumes from Video Images in Laboratory.” Flow Measurement and Instrumentation 33 (October): 188–96. https://doi.org/10.1016/j.flowmeasinst.2013.07.009. Ran, Qi-hua, Wei Li, Qian Liao, Hong-lei Tang, and Meng-yao Wang. 2016. “Application of an Automated LSPIV System in a Mountainous Stream for Continuous Flood Flow Measurements.” Hydrological Processes 30 (17): 3014–29. https://doi.org/https://doi.org/10.1002/hyp.10836. "]]
